import torch
import numpy as np
import torch.nn as nn
import pickle
import torch.nn.functional as F


class OneLayerNet(nn.Module):

    def __init__(self):
        super(OneLayerNet, self).__init__()
        self.conv1 = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1)

    def forward(self, x):
        out = self.conv1(x)
        out = F.relu(out)
        return out


batch_size = 30
num_epochs = 3

pickle_off = open("Data.pickle", "rb")
train = pickle.load(pickle_off)

model = OneLayerNet().double()

# criterion and optimizer
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.007)

total_step = len(train)
loss_list = []
acc_list = []
for epoch in range(num_epochs):
    for i, (image, move) in enumerate(train):
        # Run the forward pass
        image = image.astype(dtype=np.float32)
        move = move.astype(dtype=np.float32)
        image = torch.from_numpy(image).double().unsqueeze(dim=0).unsqueeze(dim=0)
        move = torch.from_numpy(move).double()
        output = model(image).squeeze()
        loss = criterion(output, move)
        print(loss)
        # Backprop and perform Adam optimisation
        optimizer.zero_grad()
        loss.squeeze().backward()
        optimizer.step()
